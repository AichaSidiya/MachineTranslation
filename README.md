# Machine Translation
## Machine Translation English to Arabic

<!--Title-->
## Abstract
<!--Purpose of the project-->
In an increasingly interconnected world, the demand for accurate Arabic-English translation has surged, highlighting the complexities in handling Arabic's intricate morphology and diverse linguistic structures. This research delves into various translation models, including Convolutional Neural Networks (CNNs), LSTM, Neural Machine Translation (NMT), BERT, and innovative fusion architectures like the Transformer-CNN. Each model's strengths and limitations are scrutinized through comprehensive evaluations and comparisons, unveiling their potential to address translation challenges.

The study began with a dataset comprising 20 thousand records of everyday English and Arabic translations sourced from Kaggle. The LSTM model, characterized by its sequential processing abilities, achieved a commendable accuracy of 72%, surpassing the BERT MarianMT model, which attained an accuracy of 60.25%. However, the BLEU score analysis underscored the nuanced nature of evaluation metrics, with the MarianMT model, despite its lower accuracy, exhibiting a relatively high BLEU score of 29% compared to the LSTM model's score of 0. A qualitative examination of results revealed that the BERT model demonstrated the capability to predict entire sentences, while the LSTM model predominantly produced individual propositions.

## Dataset

[Dataset](https://www.kaggle.com/code/ahmedgamal12/english-arabic-nmt/input)

## Built With
* Python

<!--Header 3 installation and launching the project-->
## How to run the program
* Clone the repository to your local machine:
```
git clone https://github.com/AichaSidiya/MachineTranslation.git
``` 
* Run on [Google Colab](https://research.google.com/colaboratory/)


## Authors
<!-- The contributors to the project-->
* [Aicha Sidiya](https://github.com/AichaSidiya)
* [Razan Almahdi](https://github.com/RazanAlmahdi)
* [Hanin Alzaher](https://github.com/hanin-az)


